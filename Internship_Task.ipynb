{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NG697EMZiPBw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/x_train.csv')\n",
        "df_1=pd.read_csv('/content/Y_train.csv')\n",
        "X_test=pd.read_csv('/content/X_test.txt', delimiter='\\t')\n",
        "Y_test=pd.read_csv('/content/y_test.txt', delimiter='\\t')\n",
        "\n",
        "# Preview the data\n",
        "print(X_test.head())\n"
      ],
      "metadata": {
        "id": "3NV2keQxpFBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load data with correct delimiter\n",
        "try:\n",
        "    X_train = pd.read_csv('/content/X_train.txt', sep=\"\\s+\", header=None)  # Handles space or tab delimiters\n",
        "    Y_train = pd.read_csv('/content/y_train.txt', sep=\"\\s+\", header=None)\n",
        "    X_test = pd.read_csv('/content/X_test.txt', sep=\"\\s+\", header=None)\n",
        "    Y_test = pd.read_csv('/content/y_test.txt', sep=\"\\s+\", header=None)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading files: {e}\")\n",
        "    raise\n",
        "\n",
        "# Check if datasets are loaded correctly\n",
        "if X_train.empty or Y_train.empty or X_test.empty or Y_test.empty:\n",
        "    raise ValueError(\"One or more datasets are empty. Check file paths and delimiters.\")\n",
        "\n",
        "# Assign column names for features and targets\n",
        "num_cols = X_train.shape[1]  # Number of columns in X_train\n",
        "X_train.columns = [f'feature_{i}' for i in range(num_cols)]\n",
        "X_test.columns = [f'feature_{i}' for i in range(num_cols)]\n",
        "Y_train.columns = ['target']\n",
        "Y_test.columns = ['target']\n",
        "\n",
        "# Check for non-numeric data and convert to numeric\n",
        "for col in X_train.columns:\n",
        "    X_train[col] = pd.to_numeric(X_train[col], errors='coerce')\n",
        "    X_test[col] = pd.to_numeric(X_test[col], errors='coerce')\n",
        "\n",
        "# Impute missing values (NaN) with the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
        "X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
        "\n",
        "# Ensure target columns are numeric\n",
        "Y_train['target'] = pd.to_numeric(Y_train['target'], errors='coerce')\n",
        "Y_test['target'] = pd.to_numeric(Y_test['target'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaN in target columns (if any)\n",
        "Y_train = Y_train.dropna().reset_index(drop=True)\n",
        "Y_test = Y_test.dropna().reset_index(drop=True)\n",
        "\n",
        "# Re-align features and targets after cleaning\n",
        "X_train = X_train.loc[Y_train.index].reset_index(drop=True)\n",
        "X_test = X_test.loc[Y_test.index].reset_index(drop=True)\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, Y_train['target'])\n",
        "\n",
        "# Predict using the test set\n",
        "Y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate individual metrics\n",
        "accuracy = accuracy_score(Y_test['target'], Y_pred)\n",
        "precision = precision_score(Y_test['target'], Y_pred, average='weighted')  # Adjust 'weighted' for multiclass\n",
        "recall = recall_score(Y_test['target'], Y_pred, average='weighted')        # Adjust 'weighted' for multiclass\n",
        "f1 = f1_score(Y_test['target'], Y_pred, average='weighted')                # Adjust 'weighted' for multiclass\n",
        "\n",
        "# Print individual scores\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\",precision)\n",
        "print(\"Recall:\" ,recall)\n",
        "print(\"F1 Score:\",f1)\n",
        "\n",
        "# ########################Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, Y_train['target'])  # Train the model\n",
        "\n",
        "# Predictions\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "rf_accuracy = accuracy_score(Y_test['target'], rf_predictions)\n",
        "rf_precision = precision_score(Y_test['target'], rf_predictions, average='weighted')\n",
        "rf_recall = recall_score(Y_test['target'], rf_predictions, average='weighted')\n",
        "rf_f1 = f1_score(Y_test['target'], rf_predictions, average='weighted')\n",
        "\n",
        "# Output\n",
        "print(\"=== Random Forest Classifier ===\")\n",
        "print(f\"Accuracy: {rf_accuracy:.2f}\")\n",
        "print(f\"Precision: {rf_precision:.2f}\")\n",
        "print(f\"Recall: {rf_recall:.2f}\")\n",
        "print(f\"F1 Score: {rf_f1:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Logistic Regression\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_model.fit(X_train, Y_train['target'])  # Train the model\n",
        "\n",
        "# Predictions\n",
        "lr_predictions = lr_model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "lr_accuracy = accuracy_score(Y_test['target'], lr_predictions)\n",
        "lr_precision = precision_score(Y_test['target'], lr_predictions, average='weighted')\n",
        "lr_recall = recall_score(Y_test['target'], lr_predictions, average='weighted')\n",
        "lr_f1 = f1_score(Y_test['target'], lr_predictions, average='weighted')\n",
        "\n",
        "# Output\n",
        "print(\"=== Logistic Regression ===\")\n",
        "print(f\"Accuracy: {lr_accuracy:.2f}\")\n",
        "print(f\"Precision: {lr_precision:.2f}\")\n",
        "print(f\"Recall: {lr_recall:.2f}\")\n",
        "print(f\"F1 Score: {lr_f1:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "# AdaBoost Classifier\n",
        "ab_model = AdaBoostClassifier(random_state=42)\n",
        "ab_model.fit(X_train, Y_train['target'])  # Train the model\n",
        "\n",
        "# Predictions\n",
        "ab_predictions = ab_model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "ab_accuracy = accuracy_score(Y_test['target'], ab_predictions)\n",
        "ab_precision = precision_score(Y_test['target'], ab_predictions, average='weighted')\n",
        "ab_recall = recall_score(Y_test['target'], ab_predictions, average='weighted')\n",
        "ab_f1 = f1_score(Y_test['target'], ab_predictions, average='weighted')\n",
        "\n",
        "# Output\n",
        "print(\"=== AdaBoost Classifier ===\")\n",
        "print(f\"Accuracy: {ab_accuracy:.2f}\")\n",
        "print(f\"Precision: {ab_precision:.2f}\")\n",
        "print(f\"Recall: {ab_recall:.2f}\")\n",
        "print(f\"F1 Score: {ab_f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TTKuOT7is16",
        "outputId": "778bfdfe-a7e9-4ff2-8c4b-f5f93d1c2eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8622327790973872\n",
            "Precision: 0.8632726592620287\n",
            "Recall: 0.8622327790973872\n",
            "F1 Score: 0.861652159274042\n",
            "=== Random Forest Classifier ===\n",
            "Accuracy: 0.93\n",
            "Precision: 0.93\n",
            "Recall: 0.93\n",
            "F1 Score: 0.93\n",
            "=== Logistic Regression ===\n",
            "Accuracy: 0.96\n",
            "Precision: 0.96\n",
            "Recall: 0.96\n",
            "F1 Score: 0.96\n",
            "=== AdaBoost Classifier ===\n",
            "Accuracy: 0.35\n",
            "Precision: 0.15\n",
            "Recall: 0.35\n",
            "F1 Score: 0.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}